---
title: "Analysis"
output:
  pdf_document: default
  html_document: 
    code_folding: hide
---

```{r setup/libraries, include=FALSE}
#setup
options(scipen = 0)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE) #echo enables
source(file = "2a Functions.R") #import functions

# libraries
library(tidyverse)
library(scales)

```

```{r open data, include=FALSE}
adata_each <- readRDS("Data/final_each2022-06-03 02:34:19.rds") %>% 
  #consider only job ads for exactly one position 
  dplyr::filter(AnzahloffeneStellen == 1) %>% 
  # english
  en_ingles()

adata_occ <- readRDS("Data/final_occupations_2022-06-11 22:45:53.rds") %>%
  #consider only job ads for exactly one position
  dplyr::filter(AnzahloffeneStellen == 1) %>% 
  # exclude cases where ID = next(ID) AND creative = next(creative) -> 2631 cases where baa description doesn't overlap with isco classification so that jobs are sorted in two categories: creative and non-creative
  dplyr::filter(!(ID == lead(ID) & creative == lead(creative))) %>%
  # exclude these 2631 cases as well
  dplyr::filter(!(ID == lead(ID) | lag(ID) == ID)) %>%
  # exclude armed forces (4 cases only)
  dplyr::filter(!(occupation_major == "Armed Forces Occupations")) %>%
  en_ingles()


adata_amr <- readRDS("Data/final_amr_2022-05-25 10:41:28.rds")

```

# Sandbox ################

```{r, job ad example, include = FALSE}
gummibaerchen <- adata_each %>% 
  dplyr::filter(200 > str_length(Stellenbeschreibung)) %>% slice(371:371) %>% 
  select(Titel, Veroeffentlicht, industry, Arbeitgeber, Lat, Lon, Stellenbeschreibung, Befristung, Staerken, Sprachkentnisse)

colnames <- colnames(gummibaerchen)
gb <- tibble(Fields = colnames, Values = t(gummibaerchen))

#xtable::xtable(gb)

```

```{r, include = FALSE}
t <- adata_each %>% dplyr::filter(50 > str_length(Stellenbeschreibung)) %>% dplyr::filter(entropy > 7)

t$Stellenbeschreibung

```


```{r}
#filter amrs

adata_occ %>% 
  group_by(AMR) %>% 
  summarise(n = n(), pop = mean(bevoelkerung)) %>% 
  ggplot(data = .) + 
  geom_point(aes(x = pop, y = n)) +
  geom_smooth(method = "lm", aes(x = pop, y = n)) +
  geom_smooth(method = "glm", aes(x = pop, y = n), )


```


# Sandbox ################


# 1 Sample

## 1.1 Descriptives

#### 1.1.1 Frequencies x population x industry
```{r, frequencies per industry, fig.height=6, fig.width=10}
#histogram of frequencies, log(population) -> scaling observable for some industries

ggplot(data = adata_occ, aes(x = log(bevoelkerung, base = 10))) +
  geom_histogram(bins = 50) +
  facet_wrap(vars(industry))

```


#### 1.1.2 Totals x industry

```{r, table totals industry}
industry_totals <- adata_occ %>% 
                            group_by(industry) %>%
                            summarise(n = n())
knitr::kable(industry_totals)

```


```{r, plot totals industry, fig.height=6, fig.width=10}

p <- ggplot(data = adata_occ %>% 
                            group_by(industry) %>%
                            summarise(n = n())) +
  geom_col(aes(x = industry, y = n)) +
  coord_flip()

p


```

### 1.1.3 Totals x Occupations

```{r, table totals occupations}
occupation_totals <- adata_occ %>% 
                            group_by(occupation_major) %>%
                            summarise(n = n())
knitr::kable(occupation_totals)

```

```{r, plot totals occupation, fig.height=6, fig.width=10}

p <- ggplot(data = adata_occ %>% 
                            group_by(occupation_major) %>%
                            summarise(n = n())) +
  geom_col(aes(x = occupation_major, y = n)) +
  coord_flip()

p
```



## 1.2 Entropy


### 1.2.1 Entropy X AMR
beta = 0.006 +- 0.0008316, super significant, 10% increase in population 0.06 % more information
```{r Entropy x AMR plot, fig.height=6, fig.width=6}
options(scipen = 0)

amr_entro <- adata_occ %>% 
  group_by(AMR, bevoelkerung) %>% 
  summarise(mean_entropy = mean(entropy, na.rm = T))


beta <- lm(log(mean_entropy) ~ log(bevoelkerung), data = amr_entro)
#summary(beta)
print(paste("beta =", beta$coefficients[2]))

pop_entropy <- ggplot(data = amr_entro, aes(x = bevoelkerung, y = mean_entropy)) +
  geom_point(alpha = 0.8, colour = "burlywood4") +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  geom_smooth(method = "lm", colour =  "darkred") +
  ggpubr::stat_cor(method = "pearson") +
  theme_minimal() +
  labs(x = "N", y = "Job complexity (Mean Entropy)")
pop_entropy


```


```{r Entropy x population plot, fig.height=8, fig.width=8}
library(scales)

options(scipen = 0)
pop_entropy <- ggplot(data = adata_occ %>% dplyr::filter(entropy > 0), 
                      aes(x = bevoelkerung, y = entropy)) +
  geom_point(alpha = 0.01) +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  #smooth line
  geom_smooth(method = "lm", colour = "darkred") +
  #correlation coefficient, y eventuell 0.1
  ggpubr::stat_cor(method = "pearson", label.y.npc = 0.0) +
  #labels
  labs(x = "N", y = "Entropy") +
  # theme 
  theme_minimal()

pop_entropy

```



### 1.2.2 Density distribution
```{r, density distribution, echo = FALSE}
amrs <- c("Salzwedel", "Berlin", "SchwÃ¤bisch Hall")

p <- ggplot(data = adata_occ %>%
              dplyr::filter(AMR %in% amrs)) +
  geom_density(aes(x = entropy, group = AMR, fill = AMR), alpha = 0.5) +
  theme_minimal()
  
p

```



## Other measures
```{r, Types x population, include=FALSE}
pop_typ <- ggplot(data = adata_occ, aes(x = log(bevoelkerung, base = 10), y = types)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  ggpubr::stat_cor(method = "pearson")

pop_typ
```

```{r, pr_noun + population, include=FALSE}
pop_noun <- ggplot(data = adata_occ, aes(x = log(bevoelkerung, base = 10), y = sents)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  ggpubr::stat_cor(method = "pearson")

pop_noun

```



# 2 Inter-Industry

## 2.1 SCALING X ENTROPY

```{r scaling/entropy, fig.height=8, fig.width=8, echo = FALSE}
options(ggrepel.max.overlaps = Inf)
#Using adata_occ

# This function takes adata which was grouped by industry beforehand and returns scaling beta for each industry
scaling <- function(industry_tibble){
  
  model1 <- lm(formula = log(n) ~ log(population),
               data = industry_tibble)
  
  return(round(model1$coefficients[2], digits = 3))
}

#group by industry, calculate summaries e.g. scaling

adata_amr <- adata_occ %>% 
  group_by(AMR, industry) %>% 
  summarise(n = n(), 
            population = mean(bevoelkerung),
            mean_entropy = mean(entropy, na.rm = T))

industry_data <- adata_amr %>% group_by(industry) %>%
  summarise(beta = scaling(cur_data()),
            mean_entropy = mean(mean_entropy, na.rm = T))

#plot, all
entropy_industry <- ggplot(data = industry_data, aes(x = mean_entropy, y = beta)) +
  geom_point(colour = "orange1") +
  ggpubr::stat_cor(method = "pearson") +
  geom_smooth(method = "lm", colour = "darkred") +
  ggrepel::geom_text_repel(aes(label = industry), ) +
  geom_hline(yintercept = 1, size = 0.2, linetype = "dotted") +
  labs(x = "Job complexity (Mean Entropy)", y = "Scaling coefficient (beta)") +
  theme_minimal()

entropy_industry

```


## 2.2 Entropy differences

10.000 sampling iterations with replacement

```{r bootstrap CIs entropy differences, include=FALSE, eval = FALSE}
library(boot)

boots_function <- function(data,index){
  d <- data[index,]
  return(mean(d$entropy, na.rm = T))  
}

boots <- adata_occ %>%
  group_split(industry) %>% 
  
  map_dfr(function(x){
    mean_entropy <- mean(x$entropy, na.rm = T)
    
    basic <- boot.ci(boot(x, boots_function, R = 10000), type = "basic")$basic
    CI.LL <- basic[4]
    CI.UL <- basic[5]
    
    res <- tibble(mean_entropy = round(mean_entropy, digits = 4),
                  CI.LL = round(CI.LL, digits = 4),
                  CI.UL = round(CI.UL, digits = 4))
    
    return(res)
    
    })
boots

saveRDS(boots, file = "Data/entropy_industry bootstrap_ci_15.06.rds")

```


```{r, plot entropy differences, fig.height=6, fig.width=8, echo = FALSE}
boots <- readRDS("Data/entropy_industry bootstrap_ci_15.06.rds")

industry_entropy_df <- adata_occ %>% 
  group_by(industry) %>% 
  summarise(mean_entropy = round(mean(entropy, na.rm = T), digits = 4))

boots_entropy <- left_join(industry_entropy_df, boots, by = "mean_entropy")

be <- ggplot(data = boots_entropy) +
  geom_col(aes(x = reorder(industry, mean_entropy), y = mean_entropy), fill = "orange1") +
  scale_y_continuous(limits=c(6, 7.5),oob = rescale_none) +

  #errorbar 
  geom_errorbar(aes(x = industry, ymin = CI.LL, ymax = CI.UL),
                  position = "dodge", 
                  width = .5) +
  #color
  coord_flip() +
  labs(x =  "Industry", 
       y = "Job complexity (Mean entropy)") + 
  theme(legend.position = "none")
    
be
```


```{r, boxplot architecture, echo = FALSE, include = FALSE}
box_pl <- ggplot(data = adata_occ %>% dplyr::filter(industry %in% c("Agriculture, forestry, horticulture", "IT, computers, telecommunication")), aes(y = entropy)) +
  geom_boxplot() +
  facet_wrap(vars(industry))
box_pl

```

## 2.3 Scaling differences

```{r, table industry beta models, echo = FALSE}
#formulate model
industry_model <- function(df) {
  lm(log(n) ~ log(bevoelkerung), data = df)
}

#group and nest
by_industry <- adata_occ %>% 
  group_by(industry, AMR) %>%
  summarise(n = n(), bevoelkerung = mean(bevoelkerung)) %>%
  nest

#add model
by_industry <- by_industry %>%
  mutate(model = map(data, industry_model))


models_by_industry <- by_industry %>% 
  mutate(tidy = map(model, broom::tidy)) %>% 
  select(-data, -model) %>%
  unnest(tidy) %>%
  dplyr::filter(term == "log(bevoelkerung)") %>%
  select(-term) %>%
  arrange(estimate)

options(scipen = 999)
knitr::kable(models_by_industry) 

#export
#xtable::xtable(models_by_industry)
```


IT vs. Food
```{r, scaling differences, IT vs. Food, fig.height=6, fig.width=6}
options(scipen = 0)
industries <- c("IT, computers, telecommunication", "Food, luxury food production")

food_it <- adata_occ %>% 
  dplyr::filter(industry %in% industries) %>%
  group_by(AMR, industry) %>%
  summarise(n_ads = n(),
            population = mean(bevoelkerung))

c <- ggplot(data = food_it, aes(x = population, y = n_ads, colour = industry)) +
  geom_point(alpha = 0.8) +
  #log scale, base 10
  scale_color_manual(values = c("Food, luxury food production" = "orange1", "IT, computers, telecommunication" = "darkred")) +
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  geom_smooth(method = "lm", aes(group = industry)) +
  ggpubr::stat_cor(method = "pearson", aes(group = industry)) +
  theme_minimal() +
  theme(legend.position="bottom")+
  labs(x = "N", y = "Number of Job Ads") 
c

```

Raw materials processing, glass, ceramics, plastics, wood vs. Food
```{r, scaling differences, Raw materials processing vs. Media, fig.height=6, fig.width=6}
industries <- c("Raw materials processing, glass,\n ceramics, plastics, wood", "Media, information services")

food_it <- adata_occ %>% 
  dplyr::filter(industry %in% industries) %>%
  group_by(AMR, industry) %>%
  summarise(n_ads = n(),
            population = mean(bevoelkerung))

c <- ggplot(data = food_it, aes(x = population, y = n_ads, colour = industry)) +
  geom_point(alpha = 0.8) +
  #log scale, base 10
  scale_color_manual(values = c("Raw materials processing, glass,\n ceramics, plastics, wood" = "orange1", "Media, information services" = "darkred")) +
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  geom_smooth(method = "lm", aes(group = industry)) +
  ggpubr::stat_cor(method = "pearson", aes(group = industry)) +
  theme_minimal() +
  theme(legend.position="bottom")+
  labs(x = "N", y = "Number of Job Ads") 
c

```


# 3 Micro: Intra-Industry

```{r descriptives, include = FALSE}

#Descriptives of all industries
adata_occ  %>% select(entropy, industry) %>% psych::describe.by(adata_occ$industry)

```

## 3.1 Micro scaling differences
Does the beta coefficient (b=0 implies proportional scaling) of entropy increase with population size in the separate industry sectors?

Raw material extraction has the highest beta: 0.004716474483
A 1% increase in population is associated with a 0.04% increase in textual information density of job ads (elasticity).
-> Negative relationships as well, e.g. IT, computers, telecommunication -> weird

```{r intra industry models, echo = FALSE}
options(scipen = 999)

industry_model <- function(df) {
  lm(log(entropy) ~ log(bevoelkerung), data = df)
}

by_industry <- adata_occ %>% 
  dplyr::filter(creative == 1) %>% #creatives??
  dplyr::filter(entropy > 0) %>% #drop cases where entropy is smaller than 1 -> undefefined if log(0)
  group_by(industry) %>%
  nest()

by_industry <- by_industry %>%
  mutate(model = map(data, industry_model))

models_by_industry <- by_industry %>% 
  mutate(tidy = map(model, broom::tidy)) %>% 
  select(-data, -model) %>%
  unnest(tidy) %>%
  dplyr::filter(term == "log(bevoelkerung)") %>%
  select(-term, -statistic) %>%
  arrange(estimate)

knitr::kable(models_by_industry)
xtable::xtable(models_by_industry, digits = c(0, 0, 4, 4, 2))


```


## 3.2 Facet micro scaling 

*with creatives*
```{r facet intra industry amr all, fig.height=10, fig.width=10, echo = FALSE}

adata_amr <- adata_occ %>% 
  #dplyr::filter(creative == 1) %>% #creatives??
  group_by(AMR, industry) %>% 
  summarise(n = n(), 
            population = mean(bevoelkerung),
            mean_entropy = mean(entropy, na.rm = T))

e <- ggplot(data = adata_amr, aes(x = population, y = mean_entropy)) +
 geom_point(alpha = 0.5, colour = "burlywood4") +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  ggpubr::stat_cor(method = "pearson", label.y.npc = 0.1) +
  geom_smooth(method = "lm") +
  facet_wrap(vars(industry)) +
  geom_smooth(method = "lm", colour =  "darkred") +
  labs(y = "Job complexity (Mean entropy)", x = "N") +
  theme_minimal()
  
e


```

*without creatives*
```{r facet intra industry amr w/o non-creatives, fig.height=10, fig.width=10, echo = FALSE}

adata_amr <- adata_occ %>% 
  dplyr::filter(creative == 1) %>% #creatives only
  group_by(AMR, industry) %>% 
  summarise(n = n(), 
            population = mean(bevoelkerung),
            mean_entropy = mean(entropy, na.rm = T))

e <- ggplot(data = adata_amr, aes(x = population, y = mean_entropy)) +
 geom_point(alpha = 0.5, colour = "burlywood4") +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  ggpubr::stat_cor(method = "pearson", label.y.npc = 0.1) +
  geom_smooth(method = "lm") +
  facet_wrap(vars(industry)) +
  geom_smooth(method = "lm", colour =  "darkred") +
  labs(y = "Job complexity (Mean entropy)", x = "N") +
  theme_minimal()
  
e


```


```{r intra industry facet pop, fig.height=6, fig.width=10, echo = FALSE}
#entropy
e <- ggplot(data = adata_occ, aes(x = bevoelkerung, y = entropy)) +
  geom_point(alpha = 0.01) +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  #smooth line
  geom_smooth(method = "lm", colour = "darkred") +
  #correlation coefficient, y eventuell 0.1
  ggpubr::stat_cor(method = "pearson", label.y.npc = 0.1) +
  geom_smooth(method = "lm", colour = "darkred") +
  facet_wrap(vars(industry))+
  theme_minimal() +
  labs(y = "Entropy", x = "N")
e

```


# 4 Inter-Occupations

## 4.1 SCALING X ENTROPY

```{r scaling x entropy, fig.height=8, fig.width=8, echo = FALSE}
options(ggrepel.max.overlaps = Inf)


# This function takes adata which was grouped by industry beforehand and returns scaling beta for each industry
scaling <- function(major_tibble){
  
  model1 <- lm(formula = log(n) ~ log(population),
               data = major_tibble)
  
  return(round(model1$coefficients[2], digits = 3))
}

#group by industry, calculate summaries e.g. scaling

adata_amr <- adata_occ %>% 
  dplyr::filter(!(occupation_major == "Skilled Agricultural, Forestry and Fishery Workers")) %>%
  group_by(AMR, occupation_major) %>% 
  summarise(n = n(), 
            population = mean(bevoelkerung),
            mean_entropy = mean(entropy, na.rm = T))

major_data <- adata_amr %>% group_by(occupation_major) %>%
  summarise(beta = scaling(cur_data()),
            mean_entropy = mean(mean_entropy, na.rm = T))

#plot, all
entropy_major <- ggplot(data = major_data, aes(x = mean_entropy, y = beta)) +
  geom_point(colour = "orange1") +
  ggpubr::stat_cor(method = "pearson") +
  geom_smooth(method = "lm", colour = "darkred") +
  ggrepel::geom_text_repel(aes(label = occupation_major), ) +
  geom_hline(yintercept = 1, size = 0.2, linetype = "dotted") +
  labs(x = "Job complexity (Mean Entropy)", y = "Scaling coefficient (beta)") +
  theme_minimal()

entropy_major


# taking out non-creative occupations


```


## 4.2 Entropy differences

```{r, major occupations CIs entropy differences, eval = FALSE, include=FALSE}
library(boot)

boots_function <- function(data,index){
  d <- data[index,]
  return(mean(d$entropy, na.rm = T))  
}

boots <- adata_occ %>%
  group_split(occupation_major) %>% 
  
  map_dfr(function(x){
    mean_entropy <- mean(x$entropy, na.rm = T)
    
    basic <- boot.ci(boot(x, boots_function, R = 1000), type = "basic")$basic
    CI.LL <- basic[4]
    CI.UL <- basic[5]
    
    res <- tibble(mean_entropy = round(mean_entropy, digits = 4),
                  CI.LL = round(CI.LL, digits = 4),
                  CI.UL = round(CI.UL, digits = 4))
    
    return(res)
    
    })
boots

saveRDS(boots, file = "Data/entropy_occupation_major_bootstrap_ci_13.06.rds")

```


```{r plot major differences bootstrap CIs, fig.height=6, fig.width=6, echo = FALSE}
boots <- readRDS("Data/entropy_occupation_major_bootstrap_ci_13.06.rds")

occupation_entropy_df <- adata_occ %>% 
  group_by(occupation_major) %>% 
  summarise(mean_entropy = round(mean(entropy, na.rm = T), digits = 4))

boots_entropy <- merge(occupation_entropy_df, boots)

be <- ggplot(data = boots_entropy) +
  geom_col(aes(x = reorder(occupation_major, mean_entropy), 
               y = mean_entropy), fill = "orange1") +
  scale_y_continuous(limits=c(6, 7.5),oob = rescale_none) +

  #errorbar 
  geom_errorbar(aes(x = occupation_major, ymin = CI.LL, ymax = CI.UL),
                  position = "dodge", 
                  width = .5) +
  #color
  coord_flip() +
  labs(x =  "Occupation", 
       y = "Job complexity (Mean entropy)") + 
  theme(legend.position = "none")
    
be
```


## 4.3 Scaling differences

```{r, table major beta models, echo = FALSE}
#formulate model
occupation_model <- function(df) {
  lm(log(n) ~ log(bevoelkerung), data = df)
}

#group and nest
by_occupation <- adata_occ %>% 
  group_by(occupation_major, AMR) %>%
  summarise(n = n(), bevoelkerung = mean(bevoelkerung)) %>%
  nest

#add model
by_occupation <- by_occupation %>%
  mutate(model = map(data, occupation_model))


n_models_by_occ <- by_occupation %>% 
  mutate(tidy = map(model, broom::tidy)) %>% 
  select(-data, -model) %>%
  unnest(tidy) %>%
  dplyr::filter(term == "log(bevoelkerung)") %>%
  select(-term) %>%
  arrange(estimate)

options(scipen = 999)
knitr::kable(n_models_by_occ) 

#export
#xtable::xtable(models_by_industry)
```



Professionals vs. Skilled Agricultural, Forestry and Fishery Workers
```{r, scaling differences, professionals vs. elementary, fig.height=6, fig.width=6}
options(scipen= 0)
occupations <- c("Professionals", "Skilled Agricultural, Forestry and Fishery Workers")

prof_elem <- adata_occ %>% 
  dplyr::filter(occupation_major %in% occupations) %>%
  group_by(AMR, occupation_major) %>%
  summarise(n_ads = n(),
            population = mean(bevoelkerung))

c <- ggplot(data = prof_elem, aes(x = population, y = n_ads, colour = occupation_major)) +
  geom_point(alpha = 0.8) +
  #log scale, base 10
  scale_color_manual(values = c("Skilled Agricultural, Forestry and Fishery Workers" = "orange1", "Professionals" = "darkred")) +
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  geom_smooth(method = "lm", aes(group = occupation_major)) +
  ggpubr::stat_cor(method = "pearson", aes(group = occupation_major)) +
  theme_minimal() +
  theme(legend.position="bottom")+
  labs(x = "N", y = "Number of Job Ads") 
c

```



# 5 Micro: Intra-Occupation

## 5.1 Creative vs. non-creative scaling differences

```{r plot complex non complex, echo = FALSE}
creatives <- adata_occ %>% 
  group_by(AMR, creative) %>%
  summarise(n = n(),
            mean_entropy = mean(entropy, na.rm = T),
            population = mean(bevoelkerung)) %>%
  drop_na(creative) %>%
  mutate(creative = as.factor(creative))

#creative occupations x amr
c <- ggplot(data = creatives, aes(x = population, y = mean_entropy, colour = creative)) +
  geom_point(alpha = 0.8) +
  #log scale, base 10
  scale_color_manual(values = c("1" = "orange1", "0" = "burlywood4")) +
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  geom_smooth(method = "lm", aes(group = creative)) +
  ggpubr::stat_cor(method = "pearson", aes(group = creative)) +
  theme_minimal() +
  labs(x = "N", y = "Job complexity (Mean entropy)", title = "Complex occupations") 
c
```


Both creative an non-creative scale over proportionally. Scaling coefficients differ between occupation types (complex vs. non creative).  
Still, results don't support the hypothesis, that scaling is stronger for creative industries.
```{r complex occupations beta models, echo = FALSE}

creative_model <- function(df) {
  lm(log(entropy) ~ log(bevoelkerung), data = df)
}

by_creative <- adata_occ %>% 
  dplyr::filter(entropy > 0) %>% #drop cases where entropy is smaller than 1 -> undefefined if log(0)
  group_by(creative) %>%
  nest()

by_creative <- by_creative %>%
  mutate(model = map(data, creative_model))

models_by_creative <- by_creative %>% 
  mutate(tidy = map(model, broom::tidy)) %>% 
  select(-data, -model) %>%
  unnest(tidy) %>%
  dplyr::filter(term == "log(bevoelkerung)") %>%
  select(-term, -statistic) %>%
  arrange(estimate)

knitr::kable(models_by_creative)
#xtable::xtable(models_by_creative, digits = c(0, 0, 4, 4, 2))





```



## 5.2 Micro scaling differences major groups

Differences in beta largely correspond to ISCO major groups. Estimates are super small. 1% increase in knowledge complexity, 0.005% increase in y

100% increase in population corresponds to 50% increase in information density -> Is this interpretation correct, yes it is I think.
Doubling city size corresponds to 50% increase in knowledge complexity for clerical support workers.

```{r, major group models/betas, echo = FALSE}
occupation_model <- function(df) {
  lm(log(entropy) ~ log(bevoelkerung), data = df)
}

by_major <- adata_occ %>% 
  dplyr::filter(entropy > 0) %>% #drop cases where entropy is smaller than 1 -> undefefined if log(0)
  #dplyr::filter(creative == 1) %>%
  group_by(occupation_major) %>%
  nest()

by_major <- by_major %>%
  mutate(model = map(data, occupation_model))

models_by_occupation <- by_major %>% 
  mutate(tidy = map(model, broom::tidy)) %>% 
  select(-data, -model) %>%
  unnest(tidy) %>%
  dplyr::filter(term == "log(bevoelkerung)") %>%
  select(-term, -statistic) %>%
  arrange(estimate)

options(scipen = 999)
knitr::kable(models_by_occupation) 

#export
#xtable::xtable(models_by_occupation, digits = c(0, 0, 4, 4, 2))
```

## 5.3 Facet micro scaling

Knowledge complexity doesn't increase within major groups. Well it does for some

```{r, facet isco major group X AMR, echo=FALSE}
#hier die betas rein

entropy_occ_maj <- adata_occ %>% 
  group_by(AMR, occupation_major) %>% 
  summarise(n = n(), 
            population = mean(bevoelkerung),
            mean_entropy = mean(entropy, na.rm = T))

o <- ggplot(data = entropy_occ_maj, aes(x = population, y = mean_entropy)) +
 geom_point(alpha = 0.5, colour = "burlywood4") +
  #log scale, base 10
  scale_x_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans = log10_trans(),
                     breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x))) +
  ggpubr::stat_cor(method = "pearson", label.y.npc = 0.1) +
  geom_smooth(method = "lm") +
  facet_wrap(vars(occupation_major)) +
  geom_smooth(method = "lm", colour =  "darkred") +
  labs(y = "Mean entropy", x = "N") +
  theme_minimal()
o


```


# 6 Maps

## 6.1 All Ads
```{r, map of all jobads, fig.height=6, fig.width=6}

amr_n <- adata_occ %>% group_by(AMR) %>% summarise(n_anzeigen = n())

amr_sf <- sf::st_read("Shapefiles/Deutschland/amr250/AMR250.shp") %>%
  inner_join(amr_n, by = "AMR")

a <- ggplot(data = amr_sf) +
  geom_sf(aes(fill=log(n_anzeigen, base = 10))) +
  coord_sf(datum = NA) +
  scale_fill_continuous(low = "white", high = "darkred") +
  labs(fill = "Number of Job Ads, log base 10") +
  theme_minimal() +
  theme(legend.position = "bottom")
  
a

```


## 6.2 Job complexity
```{r, map of knowledge complexity x AMR, echo = FALSE, fig.height=6, fig.width=6}

amr_entro <- adata_occ %>% 
  group_by(AMR, bevoelkerung) %>% 
  summarise(mean_entropy = mean(entropy, na.rm = T))

amr_sf <- sf::st_read("Shapefiles/Deutschland/amr250/AMR250.shp") %>%
  inner_join(amr_entro, by = "AMR")

a <- ggplot(data = amr_sf) +
  geom_sf(aes(fill=mean_entropy)) +
  coord_sf(datum = NA) +
  scale_fill_continuous(low = "white", high = "darkred") +
  labs(fill = "Job complexity") +
  theme_minimal() +
  theme(legend.position = "bottom")
a

```



